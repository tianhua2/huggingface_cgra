# أجهزة مخصصة للتدريب

يمكن أن يكون للأجهزة التي تستخدمها لتشغيل تدريب النماذج والاستدلال تأثير كبير على الأداء. للحصول على نظرة متعمقة حول وحدات معالجة الرسومات GPU، تأكد من مراجعة تدوينة تيم ديتمر الممتازة [blog post](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).

دعونا نلقي نظرة على بعض النصائح العملية لتهيئة وحدات معالجة الرسومات GPU.

## وحدة معالجة الرسومات GPU
عند تدريب نماذج أكبر، لديك ثلاثة خيارات أساسية:

- وحدات معالجة الرسومات GPU أكبر
- المزيد من وحدات معالجة الرسومات GPU
- المزيد من وحدة المعالجة المركزية CPU و NVMe (يتم تفريغها بواسطة [DeepSpeed-Infinity](main_classes/deepspeed#nvme-support))

دعونا نبدأ بالحالة التي لديك فيها وحدة معالجة رسومات GPU واحدة.

### الطاقة والتبريد

إذا اشتريت وحدة معالجة رسومات GPU عالية الجودة وغالية الثمن، فتأكد من تزويدها بالطاقة الصحيحة والتبريد الكافي.

**الطاقة**:

تحتوي بعض بطاقات وحدات معالجة الرسومات GPU عالية الجودة للمستهلكين على مقبس أو مقبسين للطاقة PCI-E 8-Pin. تأكد من توصيل أكبر عدد ممكن من كابلات PCI-E 8-Pin المستقلة بـ 12 فولت في البطاقة كما هو الحال مع المقابس. لا تستخدم الانقسامين الموجودين في نهاية الكابل نفسه (المعروف أيضًا باسم كابل pigtail). وهذا يعني أنه إذا كان لديك مقبسان على وحدة معالجة الرسومات GPU، فأنت تريد كابلين PCI-E 8-Pin للانتقال من وحدة الإمداد بالطاقة PSU إلى البطاقة وليس واحدًا يحتوي على موصلين PCI-E 8-Pin في النهاية! لن تحصل على الأداء الكامل من بطاقتك بخلاف ذلك.

يجب توصيل كل كابل طاقة PCI-E 8-Pin بمقبس 12 فولت على جانب وحدة الإمداد بالطاقة PSU ويمكنه توفير ما يصل إلى 150 وات من الطاقة.

قد تستخدم البطاقات الأخرى موصلات PCI-E 12-Pin، ويمكنها توصيل ما يصل إلى 500-600 وات من الطاقة.

قد تستخدم البطاقات منخفضة الجودة موصلات 6-Pin، والتي توفر ما يصل إلى 75 وات من الطاقة.

بالإضافة إلى ذلك، تريد وحدة إمداد الطاقة PSU عالية الجودة التي تحتوي على جهد كهربائي مستقر. قد لا توفر بعض الوحدات منخفضة الجودة البطاقة بجهد كهربائي مستقر تحتاجه للعمل بكامل طاقتها.

وبالطبع، يجب أن تحتوي وحدة الإمداد بالطاقة PSU على عدد كافٍ من الواط غير المستخدم لتشغيل البطاقة.

**التبريد**:

عندما ترتفع درجة حرارة وحدة معالجة الرسومات GPU، فستبدأ في تقليل سرعتها ولن تقدم أداءً كاملاً، بل ويمكن أن تتوقف عن العمل إذا ارتفعت درجة حرارتها كثيرًا.

من الصعب تحديد درجة الحرارة المثالية التي يجب السعي لتحقيقها عندما تكون وحدة معالجة الرسومات GPU مثقلة بالعمل، ولكن ربما يكون أي شيء أقل من +80 درجة مئوية جيدًا، ولكن كلما انخفضت درجة الحرارة كان ذلك أفضل - ربما يكون النطاق من 70 إلى 75 درجة مئوية ممتازًا. ومن المرجح أن يبدأ الخنق عند حوالي 84-90 درجة مئوية. ولكن بالإضافة إلى خنق الأداء، من المحتمل أن يؤدي ارتفاع درجة الحرارة لفترة طويلة جدًا إلى تقليل عمر وحدة معالجة الرسومات GPU.

بعد ذلك، دعونا نلقي نظرة على أحد أهم الجوانب عند وجود وحدات معالجة رسومات GPU متعددة: الاتصال.

### اتصال وحدات معالجة الرسومات GPU المتعددة

إذا كنت تستخدم وحدات معالجة رسومات GPU متعددة، فيمكن لطريقة اتصال البطاقات أن يكون لها تأثير كبير على إجمالي وقت التدريب. إذا كانت وحدات معالجة الرسومات GPU على نفس العقدة المادية، فيمكنك تشغيل ما يلي:

```bash
nvidia-smi topo -m
```

وسيخبرك بكيفية اتصال وحدات معالجة الرسومات GPU. على جهاز به وحدتي معالجة رسومات GPU واللتان متصلتان بـ NVLink، فمن المحتمل أن ترى شيئًا مثل:

```
        GPU0    GPU1    CPU Affinity    NUMA Affinity
GPU0     X      NV2     0-23            N/A
GPU1    NV2      X      0-23            N/A
```

على جهاز مختلف بدون NVLink، قد نرى:
```
        GPU0    GPU1    CPU Affinity    NUMA Affinity
GPU0     X      PHB     0-11            N/A
GPU1    PHB      X      0-11            N/A
```

يتضمن التقرير هذا الشرح:

```
  X    = Self
  SYS  = Connection traversing PCIe as well as the SMP interconnect between NUMA nodes (e.g., QPI/UPI)
  NODE = Connection traversing PCIe as well as the interconnect between PCIe Host Bridges within a NUMA node
  PHB  = Connection traversing PCIe as well as a PCIe Host Bridge (typically the CPU)
  PXB  = Connection traversing multiple PCIe bridges (without traversing the PCIe Host Bridge)
  PIX  = Connection traversing at most a single PCIe bridge
  NV#  = Connection traversing a bonded set of # NVLinks
```

لذا فإن التقرير الأول `NV2` يخبرنا بأن وحدات معالجة الرسومات GPU متصلة بواسطة رابطين NVLink، والتقرير الثاني `PHB` لدينا إعداد PCIe+Bridge على مستوى المستهلك النموذجي.

تحقق من نوع الاتصال الذي لديك في إعدادك. سيجعل بعضها الاتصال بين البطاقات أسرع (مثل NVLink)، بينما سيجعلها البعض الآخر أبطأ (مثل PHB).

اعتمادًا على نوع حل قابلية التوسع المستخدم، قد يكون لسرعة الاتصال تأثير كبير أو صغير. إذا كان على وحدات معالجة الرسومات GPU المزامنة نادرًا، كما هو الحال في DDP، فإن تأثير الاتصال البطيء سيكون أقل أهمية. إذا كان على وحدات معالجة الرسومات GPU إرسال الرسائل إلى بعضها البعض بشكل متكرر، كما هو الحال في ZeRO-DP، فإن اتصال أسرع يصبح فائق الأهمية لتحقيق تدريب أسرع.

#### NVlink

[NVLink](https://en.wikipedia.org/wiki/NVLink) هو رابط اتصالات متعدد المسارات قريب المدى متسلسل يعتمد على الأسلاك طورته شركة Nvidia.

يوفر كل جيل جديد عرض نطاق ترددي أسرع، على سبيل المثال، إليك اقتباس من [Nvidia Ampere GA102 GPU Architecture](https://www.nvidia.com/content/dam/en-zz/Solutions/geforce/ampere/pdf/NVIDIA-ampere-GA102-GPU-Architecture-Whitepaper-V1.pdf):

> NVLink® من الجيل الثالث
> تستخدم وحدات معالجة الرسومات GA102 واجهة NVLink من الجيل الثالث من NVIDIA، والتي تتضمن أربعة روابط x4،
> يوفر كل رابط 14.0625 جيجابايت/ثانية من عرض النطاق الترددي في كل اتجاه بين وحدتي معالجة الرسومات GPU. توفر أربعة
> روابط 56.25 جيجابايت/ثانية من عرض النطاق الترددي في كل اتجاه، و112.5 جيجابايت/ثانية من إجمالي عرض النطاق الترددي
> بين وحدتي معالجة الرسومات GPU. يمكن توصيل وحدتي معالجة الرسومات RTX 3090 معًا لـ SLI باستخدام NVLink.
> (ملاحظة: لا يتم دعم تكوينات SLI ثلاثية الاتجاهات ورباعية الاتجاهات.)

لذا، كلما حصلت على قيمة أعلى لـ `X` في تقرير `NVX` في إخراج `nvidia-smi topo -m`، كان ذلك أفضل. سيعتمد الجيل على بنية وحدة معالجة الرسومات GPU الخاصة بك.

دعونا نقارن تنفيذ تدريب نموذج اللغة openai-community/gpt2 عبر عينة صغيرة من wikitext.

النتائج هي:


| NVlink | الوقت |
| -----  | ---: |
| نعم      | 101 ثانية |
| لا      | 131 ثانية |


يمكنك أن ترى أن NVLink يكمل التدريب بنسبة ~23% أسرع. في المعيار الثاني، نستخدم `NCCL_P2P_DISABLE=1` لإخبار وحدات معالجة الرسومات GPU بعدم استخدام NVLink.

فيما يلي كود المعيار المرجعي الكامل والإخراج:

```bash
# DDP w/ NVLink

rm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 torchrun \
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path openai-community/gpt2 \
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train \
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{'train_runtime': 101.9003, 'train_samples_per_second': 1.963, 'epoch': 0.69}

# DDP w/o NVLink

rm -r /tmp/test-clm; CUDA_VISIBLE_DEVICES=0,1 NCCL_P2P_DISABLE=1 torchrun \
--nproc_per_node 2 examples/pytorch/language-modeling/run_clm.py --model_name_or_path openai-community/gpt2 \
--dataset_name wikitext --dataset_config_name wikitext-2-raw-v1 --do_train
--output_dir /tmp/test-clm --per_device_train_batch_size 4 --max_steps 200

{'train_runtime': 131.4367, 'train_samples_per_second': 1.522, 'epoch': 0.69}
```

الأجهزة: 2x TITAN RTX 24 جيجابايت لكل منهما + NVlink مع رابطين NVLink (`NV2` في `nvidia-smi topo -m`)
البرمجيات: `pytorch-1.8-to-be` + `cuda-11.0` / `transformers==4.3.0.dev0`