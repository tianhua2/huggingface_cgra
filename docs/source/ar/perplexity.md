# ุญูุฑุฉ ุงูููุงุฐุฌ ุฐุงุช ุงูุทูู ุงูุซุงุจุช

[[open-in-colab]]

ุญูุฑุฉ (PPL) ูู ูุงุญุฏุฉ ูู ุฃูุซุฑ ุงูููุงููุณ ุดููุนูุง ูุชูููู ููุงุฐุฌ ุงููุบุฉ. ูุจู ุงูุบูุต ูู ุงูุชูุงุตููุ ูุฌุจ ุฃู ููุงุญุธ ุฃู ุงููููุงุณ ููุทุจู ุชุญุฏูุฏูุง ุนูู ููุงุฐุฌ ุงููุบุฉ ุงูููุงุณูููุฉ (ููุทูู ุนูููุง ุฃุญูุงููุง ููุงุฐุฌ ุงููุบุฉ ุงูุฐุงุชูุฉ ุงูุชุฑุฌุนูุฉ ุฃู ุงูุณุจุจูุฉ) ููู ุบูุฑ ูุญุฏุฏุฉ ุฌูุฏูุง ูููุงุฐุฌ ุงููุบุฉ ุงููููุนุฉ ูุซู BERT (ุฑุงุฌุน [ููุฎุต ุงูููุงุฐุฌ](model_summary)).

ุชูุนุฑููู ุงูุญูุฑุฉ ุนูู ุฃููุง ุงูุฃุณ ุงููุทุฑูุญ ูู ูุชูุณุท ุงูููุบุงุฑูุชู ุงูุงุญุชูุงูู ููุชุชุงููุฉ. ุฅุฐุง ูุงู ูุฏููุง ุชุณูุณู ูููุฒ \\(X = (x_0, x_1, \dots, x_t)\\)ุ ูุฅู ุญูุฑุฉ \\(X\\) ููุ

$$\text{PPL}(X) = \exp \left\{ {-\frac{1}{t}\sum_i^t \log p_\theta (x_i|x_{<i}) } \right\}$$

ุญูุซ \\(\log p_\theta (x_i|x_{<i})\\) ูู ุงูููุบุงุฑูุชู ุงูุงุญุชูุงูู ููุฑูุฒ i ุงููุดุฑูุท ุจุงูุฑููุฒ ุงูุณุงุจูุฉ \\(x_{<i}\\) ููููุง ููููุฐุฌูุง. ููู ุงููุงุญูุฉ ุงูุจุฏูููุฉุ ูููู ุงุนุชุจุงุฑูุง ุชูููููุง ููุฏุฑุฉ ุงููููุฐุฌ ุนูู ุงูุชูุจุค ุจุดูู ููุญุฏ ุจูู ูุฌููุนุฉ ูู ุงูุฑููุฒ ุงููุญุฏุฏุฉ ูู ูุฌููุนุฉ ูู ุงูุจูุงูุงุช. ููู ุงูููู ุฃู ููุงุญุธ ุฃู ูุฐุง ูุนูู ุฃู ุฅุฌุฑุงุก ุงูุชูููุฒ ูู ุชุฃุซูุฑ ูุจุงุดุฑ ุนูู ุญูุฑุฉ ุงููููุฐุฌุ ูุงูุชู ูุฌุจ ุฃู ุชุคุฎุฐ ุฏุงุฆููุง ูู ุงูุงุนุชุจุงุฑ ุนูุฏ ููุงุฑูุฉ ุงูููุงุฐุฌ ุงููุฎุชููุฉ.

ูุฐุง ูุนุงุฏู ุฃูุถูุง ุฃุณ ูููุฉ ุงูุงูุชุฑูุจูุง ุงููุดุชุฑูุฉ ุจูู ุงูุจูุงูุงุช ูุชูุจุคุงุช ุงููููุฐุฌ. ููุฒูุฏ ูู ุงูุจุฏูููุงุช ุญูู ุงูุญูุฑุฉ ูุนูุงูุชูุง ุจู Bits Per Character (BPC) ูุถุบุท ุงูุจูุงูุงุชุ ุชุญูู ูู ูุฐู [ุงูุชุฏูููุฉ ุงูุฑุงุฆุนุฉ ุนูู The Gradient](https://thegradient.pub/understanding-evaluation-metrics-for-language-models/).

## ุญุณุงุจ PPL ูุน ุงูููุงุฐุฌ ุฐุงุช ุงูุทูู ุงูุซุงุจุช

ุฅุฐุง ูู ููู ูููุฏูู ุจุญุฌู ุณูุงู ุงููููุฐุฌุ ูุณูููู ุจุชูููู ุญูุฑุฉ ุงููููุฐุฌ ุนู ุทุฑูู ุชูููู ุชุณูุณู ุจุดูู ุฐุงุชู ุชุฑุฌุนู ูุงูุงุดุชูุงู ุงูุดุฑุทู ููุชุณูุณู ุงููุฑุนู ุงูุณุงุจู ุจุงููุงูู ูู ูู ุฎุทูุฉุ ููุง ูู ููุถุญ ุฃุฏูุงู.

<img width="600" alt="Full decomposition of a sequence with unlimited context length" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_full.gif"/>

ููุน ุฐููุ ุนูุฏ ุงูุนูู ูุน ุงูููุงุฐุฌ ุงูุชูุฑูุจูุฉุ ุนุงุฏุฉ ูุง ูููู ูุฏููุง ููุฏ ุนูู ุนุฏุฏ ุงูุฑููุฒ ุงูุชู ูููู ูููููุฐุฌ ูุนุงูุฌุชูุง. ุนูู ุณุจูู ุงููุซุงูุ ุชุญุชูู ุฃูุจุฑ ูุณุฎุฉ ูู [GPT-2](model_doc/gpt2) ุนูู ุทูู ุซุงุจุช ูุจูุบ 1024 ุฑูุฒูุงุ ูุฐูู ูุง ูููููุง ุญุณุงุจ \\(p_\theta(x_t|x_{<t})\\) ูุจุงุดุฑุฉ ุนูุฏูุง \\(t\\) ุฃูุจุฑ ูู 1024.

ุจุฏูุงู ูู ุฐููุ ูุชู ุนุงุฏุฉู ุชูุณูู ุงูุชุณูุณู ุฅูู ุชุณูุณูุงุช ูุฑุนูุฉ ุชุณุงูู ุญุฌู ุงูุฅุฏุฎุงู ุงูุฃูุตู ูููููุฐุฌ. ุฅุฐุง ูุงู ุญุฌู ุงูุฅุฏุฎุงู ุงูุฃูุตู ูููููุฐุฌ ูู \\(k\\)ุ ูุฅููุง ูููู ุจุนุฏ ุฐูู ุจุชูุฑูุจ ุงุญุชูุงู ุงูุฑูุฒ \\(x_t\\) ุนู ุทุฑูู ุงูุงุดุชูุงู ุงูุดุฑุทู ููุท ุจุงููุณุจุฉ ุฅูู \\(k-1\\) ูู ุงูุฑููุฒ ุงูุชู ุชุณุจูู ุจุฏูุงู ูู ุงูุณูุงู ุจุฃูููู. ุนูุฏ ุชูููู ุญูุฑุฉ ุงููููุฐุฌ ูุชุณูุณู ูุงุ ูุฅู ุฃุญุฏ ุงูุฃุณุงููุจ ุงููุบููุฉ ููููู ุฏูู ุงููุณุชูู ุงูุฃูุซู ูู ุชูุณูู ุงูุชุณูุณู ุฅูู ูุทุน ุบูุฑ ูุชุตูุฉ ูุฅุถุงูุฉ ุงูููุบุงุฑูุชูุงุช ุงูููููุฉ ููู ุฌุฒุก ุจุดูู ูุณุชูู.

<img width="600" alt="Suboptimal PPL not taking advantage of full available context" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_chunked.gif"/>
<img width="600" alt="Suboptimal PPL not taking advantage of full available context" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_chunked.gif"/>

ูุฐุง ุณุฑูุน ุงูุญุณุงุจ ูุฃู ุญูุฑุฉ ูู ุฌุฒุก ูููู ุญุณุงุจูุง ูู ุชูุฑูุฑ ูุงุญุฏุ ููููู ููุซู ุชูุฑูุจูุง ุถุนูููุง ูุญูุฑุฉ ุงูุชูููู ุงููุงูู ูุณูุคุฏู ุนุงุฏุฉู ุฅูู PPL ุฃุนูู (ุฃุณูุฃ) ูุฃู ุงููููุฐุฌ ุณูููู ูุฏูู ุณูุงู ุฃูู ูู ูุนุธู ุฎุทูุงุช ุงูุชูุจุค.

ุจุฏูุงู ูู ุฐููุ ูุฌุจ ุชูููู ุญูุฑุฉ ุงูููุงุฐุฌ ุฐุงุช ุงูุทูู ุงูุซุงุจุช ุจุงุณุชุฎุฏุงู ุฅุณุชุฑุงุชูุฌูุฉ ุงููุงูุฐุฉ ุงูููุฒููุฉ. ูููุทูู ูุฐุง ุนูู ุชุญุฑูู ูุงูุฐุฉ ุงูุณูุงู ุจุดูู ูุชูุฑุฑ ุจุญูุซ ูููู ูููููุฐุฌ ุณูุงู ุฃูุจุฑ ุนูุฏ ุฅุฌุฑุงุก ูู ุชูุจุค.

<img width="600" alt="Sliding window PPL taking advantage of all available context" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/ppl_sliding.gif"/>

ูุฐุง ุชูุฑูุจ ุฃูุซู ููุชูููู ุงูุญูููู ูุงุญุชูุงููุฉ ุงูุชุณูุณู ูุณูุคุฏู ุนุงุฏุฉู ุฅูู ูุชูุฌุฉ ุฃูุถู. ุงูุฌุงูุจ ุงูุณูุจู ูู ุฃูู ูุชุทูุจ ุชูุฑูุฑูุง ููุฃูุงู ููู ุฑูุฒ ูู ูุฌููุนุฉ ุงูุจูุงูุงุช. ุญู ูุณุท ุนููู ุฌูุฏ ูู ุงุณุชุฎุฏุงู ูุงูุฐุฉ ููุฒููุฉ ุฐุงุช ุฎุทูุฉุ ุญูุซ ูุชู ุชุญุฑูู ุงูุณูุงู ุจุฎุทูุงุช ุฃูุจุฑ ุจุฏูุงู ูู ุงูุงูุฒูุงู ุจููุฏุงุฑ 1 ุฑูุฒ ูู ูู ูุฑุฉ. ูุณูุญ ุฐูู ุจุฅุฌุฑุงุก ุงูุญุณุงุจ ุจุดูู ุฃุณุฑุน ูุน ุฅุนุทุงุก ุงููููุฐุฌ ุณูุงููุง ูุจูุฑูุง ููุชูุจุคุงุช ูู ูู ุฎุทูุฉ.

## ูุซุงู: ุญุณุงุจ ุงูุญูุฑุฉ ูุน GPT-2 ูู ๐ค Transformers

ุฏุนููุง ููุถุญ ูุฐู ุงูุนูููุฉ ูุน GPT-2.

```python
from transformers import GPT2LMHeadModel, GPT2TokenizerFast

device = "cuda"
model_id = "openai-community/gpt2-large"
model = GPT2LMHeadModel.from_pretrained(model_id).to(device)
tokenizer = GPT2TokenizerFast.from_pretrained(model_id)
```

ุณูููู ุจุชุญููู ูุฌููุนุฉ ุจูุงูุงุช WikiText-2 ูุชูููู ุงูุญูุฑุฉ ุจุงุณุชุฎุฏุงู ุจุนุถ ุฅุณุชุฑุงุชูุฌูุงุช ุงููุงูุฐุฉ ุงูููุฒููุฉ ุงููุฎุชููุฉ. ูุธุฑูุง ูุฃู ูุฐู ุงููุฌููุนุฉ ุตุบูุฑุฉ ููููู ููุท ุจุชูุฑูุฑ ูุงุญุฏ ุนูู ุงููุฌููุนุฉุ ููููููุง ุจุจุณุงุทุฉ ุชุญููู ุงููุฌููุนุฉ ูุชุฑููุฒูุง ุจุงููุงูู ูู ุงูุฐุงูุฑุฉ.

```python
from datasets import load_dataset

test = load_dataset("wikitext", "wikitext-2-raw-v1", split="test")
encodings = tokenizer("\n\n".join(test["text"]), return_tensors="pt")
```

ูุน ๐ค Transformersุ ูููููุง ุจุจุณุงุทุฉ ุชูุฑูุฑ `input_ids` ูู `labels` ุฅูู ูููุฐุฌูุงุ ููุชู ุฅุฑุฌุงุน ูุชูุณุท ุงูููุบุงุฑูุชู ุงูุงุญุชูุงูู ุงูุณูุจู ููู ุฑูุฒ ูุฎุณุงุฑุฉ. ููุน ุฐููุ ูุน ููุฌ ุงููุงูุฐุฉ ุงูููุฒููุฉ ูุฏููุงุ ููุงู ุชุฏุงุฎู ูู ุงูุฑููุฒ ุงูุชู ููุฑุฑูุง ุฅูู ุงููููุฐุฌ ูู ูู ุชูุฑุงุฑ. ูุง ูุฑูุฏ ุชุถููู ุงูููุบุงุฑูุชู ุงูุงุญุชูุงูู ููุฑููุฒ ุงูุชู ูุชุนุงูู ูุนูุง ูุณูุงู ูู ุฎุณุงุฑุชูุงุ ูุฐุง ูููููุง ุชุนููู ูุฐู ุงูุฃูุฏุงู ุฅูู `-100` ุจุญูุซ ูุชู ุชุฌุงูููุง. ูุง ููู ูู ูุซุงู ุนูู ููููุฉ ุงูููุงู ุจุฐูู ูุน ุฎุทูุฉ ูู `512`. ููุฐุง ูุนูู ุฃู ุงููููุฐุฌ ุณูููู ูุฏูู 512 ุฑูุฒูุง ุนูู ุงูุฃูู ููุณูุงู ุนูุฏ ุญุณุงุจ ุงูุงุญุชูุงููุฉ ุงูุดุฑุทูุฉ ูุฃู ุฑูุฒ ูุงุญุฏ (ุดุฑูุทุฉ ุฃู ุชููู ููุงู 512 ุฑูุฒูุง ุณุงุจููุง ูุชุงุญูุง ููุงุดุชูุงู).

```python
import torch
from tqdm import tqdm

max_length = model.config.n_positions
stride = 512
seq_len = encodings.input_ids.size(1)

nlls = []
prev_end_loc = 0
for begin_loc in tqdm(range(0, seq_len, stride)):
    end_loc = min(begin_loc + max_length, seq_len)
    trg_len = end_loc - prev_end_loc  # ูุฏ ุชููู ูุฎุชููุฉ ุนู ุงูุฎุทูุฉ ูู ุงูุญููุฉ ุงูุฃุฎูุฑุฉ
    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)
    target_ids = input_ids.clone()
    target_ids[:, :-trg_len] = -100

    with torch.no_grad():
        outputs = model(input_ids, labels=target_ids)

        # ูุชู ุญุณุงุจ ุงูุฎุณุงุฑุฉ ุจุงุณุชุฎุฏุงู CrossEntropyLoss ุงูุฐู ูููู ุจุงููุชูุณุท ุนูู ุงูุชุตูููุงุช ุงูุตุญูุญุฉ
        # ูุงุญุธ ุฃู ุงููููุฐุฌ ูุญุณุจ ุงูุฎุณุงุฑุฉ ุนูู trg_len - 1 ูู ุงูุชุตูููุงุช ููุทุ ูุฃูู ูุชุญูู ุฏุงุฎูููุง ุฅูู ุงููุณุงุฑ ุจูุงุณุทุฉ 1.
        neg_log_likelihood = outputs.loss

    nlls.append(neg_log_likelihood)

    prev_end_loc = end_loc
    if end_loc == seq_len:
        break

ppl = torch.exp(torch.stack(nlls).mean())
```

ุฅู ุชุดุบูู ูุฐุง ูุน ุทูู ุงูุฎุทูุฉ ูุณุงูู ุทูู ุงูุฅุฏุฎุงู ุงูุฃูุตู ูุนุงุฏู ุฅุณุชุฑุงุชูุฌูุฉ ุงููุงูุฐุฉ ุบูุฑ ุงูููุฒููุฉ ูุบูุฑ ุงููุซูู ุงูุชู ูุงูุดูุงูุง ุฃุนูุงู. ููููุง ุตุบุฑุช ุงูุฎุทูุฉุ ุฒุงุฏ ุงูุณูุงู ุงูุฐู ุณูููู ูุฏู ุงููููุฐุฌ ูู ุฅุฌุฑุงุก ูู ุชูุจุคุ ููููุง ูุงูุช ุงูุญูุฑุฉ ุงููุจูุบ ุนููุง ุฃูุถู ุนุงุฏุฉู.

ุนูุฏูุง ูููู ุจุชุดุบูู ูุง ุณุจู ุจุงุณุชุฎุฏุงู `stride = 1024`ุ ุฃู ุจุฏูู ุชุฏุงุฎูุ ุชููู ูุชูุฌุฉ PPL ูู `19.44`ุ ููู ูุง ููุงุซู `19.93` ุงููุจูุบ ุนููุง ูู ูุฑูุฉ GPT-2. ูู ุฎูุงู ุงุณุชุฎุฏุงู `stride = 512` ูุจุงูุชุงูู ุงุณุชุฎุฏุงู ุฅุณุชุฑุงุชูุฌูุฉ ุงููุงูุฐุฉ ุงูููุฒููุฉ ูุฏููุงุ ููุฎูุถ ูุฐุง ุฅูู `16.45`. ูุฐู ุงููุชูุฌุฉ ููุณุช ููุท ุฃูุถูุ ูููููุง ูุญุณูุจุฉ ุจุทุฑููุฉ ุฃูุฑุจ ุฅูู ุงูุชูููู ุงูุฐุงุชู ุงูุชุฑุฌุนู ุงูุญูููู ูุงุญุชูุงููุฉ ุงูุชุณูุณู.