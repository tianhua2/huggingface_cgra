# ما الذي يمكن أن تفعله مكتبة 🤗 Transformers؟

🤗 Transformers هي مكتبة تضم نماذج مُدربة مسبقًا رائدة في مجال معالجة اللغات الطبيعية (NLP)، ورؤية الكمبيوتر، ومعالجة الصوت والمهام الكلامية. لا تحتوي المكتبة على نماذج المحول فحسب، بل تحتوي أيضًا على نماذج غير محولة مثل الشبكات التلافيفية الحديثة لمهام رؤية الكمبيوتر. إذا نظرت إلى بعض أكثر المنتجات الاستهلاكية شيوعًا اليوم، مثل الهواتف الذكية والتطبيقات وأجهزة التلفزيون، فمن المحتمل أن يكون هناك نوع من تقنية التعلم العميق وراءها. هل تريد إزالة كائن الخلفية من صورة التقطتها بهاتفك الذكي؟ هذا مثال على مهمة التجزئة الشاملة (لا تقلق إذا لم تكن تعرف معنى ذلك بعد، فسوف نصفه في الأقسام التالية!).

تقدم هذه الصفحة نظرة عامة على مهام الكلام والصوت ورؤية الكمبيوتر ومعالجة اللغات الطبيعية المختلفة التي يمكن حلها باستخدام مكتبة 🤗 Transformers في ثلاثة أسطر فقط من التعليمات البرمجية!

## الصوت

تختلف مهام معالجة الصوت والكلام قليلاً عن الطرائق الأخرى بشكل أساسي لأن الصوت كإدخال هو إشارة مستمرة. على عكس النص، لا يمكن تقسيم الموجة الصوتية الخام بشكل مرتب في أجزاء منفصلة بالطريقة التي يمكن بها تقسيم الجملة إلى كلمات. وللتغلب على هذا، يتم عادةً أخذ عينات من الإشارة الصوتية الخام على فترات منتظمة. إذا قمت بأخذ المزيد من العينات ضمن فترة زمنية، يكون معدل العينات أعلى، ويشبه الصوت بشكل أوثق مصدر الصوت الأصلي.

قامت الطرق السابقة بمعالجة الصوت لاستخراج الميزات المفيدة منه. أصبح من الشائع الآن البدء بمهام معالجة الصوت والكلام عن طريق إدخال الموجة الصوتية الخام مباشرة في مشفر الميزات لاستخراج تمثيل صوتي. وهذا يبسط خطوة المعالجة المسبقة ويسمح للنموذج بتعلم أهم الميزات.

### تصنيف الصوت

تصنيف الصوت هو مهمة تقوم بوضع علامات على بيانات الصوت من مجموعة محددة مسبقًا من الفئات. إنه فئة واسعة مع العديد من التطبيقات المحددة، والتي تشمل:

* تصنيف المشهد الصوتي: وضع علامة على الصوت باستخدام تسمية المشهد ("المكتب"، "الشاطئ"، "الملعب")
* اكتشاف الأحداث الصوتية: وضع علامة على الصوت باستخدام تسمية حدث صوتي ("بوق السيارة"، "نداء الحوت"، "كسر الزجاج")
* وضع العلامات: وضع علامة على الصوت الذي يحتوي على أصوات متعددة (أغاني الطيور، وتحديد المتحدث في اجتماع)
* تصنيف الموسيقى: وضع علامة على الموسيقى بتسمية النوع ("معدن"، "هيب هوب"، "البلد")

```py
>>> from transformers import pipeline

>>> classifier = pipeline(task="audio-classification", model="superb/hubert-base-superb-er")
>>> preds = classifier("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.4532, 'label': 'hap'},
 {'score': 0.3622, 'label': 'sad'},
 {'score': 0.0943, 'label': 'neu'},
 {'score': 0.0903, 'label': 'ang'}]
```

### التعرف التلقائي على الكلام

يقوم التعرف التلقائي على الكلام (ASR) بنقل الكلام إلى نص. إنه أحد أكثر المهام الصوتية شيوعًا ويرجع ذلك جزئيًا إلى أن الكلام هو شكل طبيعي جدًا من أشكال التواصل البشري. اليوم، يتم تضمين أنظمة ASR في منتجات التكنولوجيا "الذكية" مثل مكبرات الصوت والهواتف والسيارات. يمكننا أن نطلب من مساعدينا الافتراضيين تشغيل الموسيقى، وضبط التذكيرات، وإخبارنا بالطقس.
ولكن أحد التحديات الرئيسية التي ساعدت عليها هندسات المحول هي اللغات منخفضة الموارد. من خلال التدريب المسبق على كميات كبيرة من بيانات الكلام، يمكن أن يؤدي ضبط دقة النموذج على ساعة واحدة فقط من بيانات الكلام المُوسم في لغة منخفضة الموارد إلى نتائج عالية الجودة مقارنة بأنظمة ASR السابقة التي تم تدريبها على بيانات موسومة أكثر بـ 100 مرة.

```py
>>> from transformers import pipeline

>>> transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-small")
>>> transcriber("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
{'text': ' I have a dream that one day this nation will rise up and live out the true meaning of its creed.'}
```

## رؤية الكمبيوتر

كانت إحدى مهام رؤية الكمبيوتر الأولى والأكثر نجاحًا في التعرف على صور رموز البريد باستخدام [شبكة عصبية تلافيفية (CNN)](glossary#convolution). تتكون الصورة من بكسلات، ولكل بكسل قيمة رقمية. وهذا يجعل من السهل تمثيل صورة كمصفوفة من قيم البكسل. يصف كل مزيج خاص من قيم البكسل ألوان الصورة.

هناك طريقتان عامتان يمكن من خلالهما حل مهام رؤية الكمبيوتر:

1. استخدام التلافيف لتعلم الميزات الهرمية لصورة من الميزات منخفضة المستوى إلى الأشياء المجردة عالية المستوى.
2. تقسيم صورة إلى رقع واستخدام محول ليتعلم تدريجياً كيف ترتبط كل رقعة صورة ببعضها البعض لتشكيل صورة. على عكس النهج التصاعدي الذي تفضله شبكة CNN، هذا يشبه إلى حد ما البدء بصورة ضبابية ثم جعلها تدريجياً أكثر وضوحًا.

### تصنيف الصور

يقوم تصنيف الصور بوضع علامة على صورة كاملة من مجموعة محددة مسبقًا من الفئات. مثل معظم مهام التصنيف، هناك العديد من حالات الاستخدام العملية لتصنيف الصور، والتي تشمل:

* الرعاية الصحية: وضع علامة على الصور الطبية للكشف عن الأمراض أو مراقبة صحة المريض
* البيئة: وضع علامة على صور الأقمار الصناعية لرصد إزالة الغابات، أو إبلاغ إدارة الأراضي البرية أو اكتشاف حرائق الغابات
* الزراعة: وضع علامة على صور المحاصيل لمراقبة صحة النبات أو صور الأقمار الصناعية لرصد استخدام الأراضي
* علم البيئة: وضع علامة على صور الأنواع الحيوانية أو النباتية لرصد أعداد الحياة البرية أو تتبع الأنواع المهددة بالانقراض

```py
>>> from transformers import pipeline

>>> classifier = pipeline(task="image-classification")
>>> preds = classifier(
...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> print(*preds, sep="\n")
{'score': 0.4335, 'label': 'lynx, catamount'}
{'score': 0.0348, 'label': 'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor'}
{'score': 0.0324, 'label': 'snow leopard, ounce, Panthera uncia'}
{'score': 0.0239, 'label': 'Egyptian cat'}
{'score': 0.0229, 'label': 'tiger cat'}
```

### كشف الأشياء

على عكس تصنيف الصور، يقوم كشف الأشياء بتحديد عدة أشياء داخل صورة ومواضع الأشياء في صورة (يحددها مربع الإحاطة). بعض تطبيقات كشف الأشياء تشمل:

* المركبات ذاتية القيادة: اكتشاف الأشياء المرورية اليومية مثل المركبات الأخرى والمشاة وإشارات المرور
* الاستشعار عن بعد: مراقبة الكوارث، والتخطيط الحضري، والتنبؤ بالطقس
* اكتشاف العيوب: اكتشاف الشقوق أو الأضرار الهيكلية في المباني، وعيوب التصنيع

```py
>>> from transformers import pipeline

>>> detector = pipeline(task="object-detection")
>>> preds = detector(
...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"], "box": pred["box"]} for pred in preds]
>>> preds
[{'score': 0.9865,
  'label': 'cat',
  'box': {'xmin': 178, 'ymin': 154, 'xmax': 882, 'ymax': 598}}]
```

### تجزئة الصورة

تجزئة الصورة هي مهمة على مستوى البكسل تقوم بتخصيص كل بكسل في صورة لفئة. إنه يختلف عن كشف الأشياء، والذي يستخدم صناديق الإحاطة لوضع علامات على الأشياء والتنبؤ بها في صورة لأن التجزئة أكثر دقة. يمكن لتجزئة الكائنات اكتشاف الأشياء على مستوى البكسل. هناك عدة أنواع من تجزئة الصور:

* تجزئة مثيلات: بالإضافة إلى وضع علامة على فئة كائن، فإنه أيضًا يضع علامات على كل مثيل مميز لكائن ("الكلب-1"، "الكلب-2")
* التجزئة الشاملة: مزيج من التجزئة الدلالية ومثيلات التجزئة؛ فهو يضع علامة على كل بكسل مع فئة دلالية **و** كل مثيل مميز لكائن

تساعد مهام التجزئة في المركبات ذاتية القيادة على إنشاء خريطة على مستوى البكسل للعالم من حولها حتى تتمكن من التنقل بأمان حول المشاة والمركبات الأخرى. كما أنها مفيدة للتصوير الطبي، حيث يمكن لدقة المهمة أن تساعد في تحديد الخلايا أو ميزات الأعضاء غير الطبيعية. يمكن أيضًا استخدام تجزئة الصور في التجارة الإلكترونية لتجربة الملابس افتراضيًا أو إنشاء تجارب الواقع المعزز من خلال تراكب الأشياء في العالم الحقيقي من خلال الكاميرا الخاصة بك.

```py
>>> from transformers import pipeline

>>> segmenter = pipeline(task="image-segmentation")
>>> preds = segmenter(
...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> print(*preds, sep="\n")
{'score': 0.9879, 'label': 'LABEL_184'}
{'score': 0.9973, 'label': 'snow'}
{'score': 0.9972, 'label': 'cat'}
```

### تقدير العمق

يقوم تقدير العمق بالتنبؤ بمسافة كل بكسل في صورة من الكاميرا. تعد هذه المهمة لرؤية الكمبيوتر مهمة بشكل خاص لفهم المشهد وإعادة الإعمار. على سبيل المثال، في السيارات ذاتية القيادة، تحتاج المركبات إلى فهم مدى بعد الأشياء مثل المشاة ولافتات المرور والمركبات الأخرى لتجنب العقبات والاصطدامات. تساعد معلومات العمق أيضًا في بناء التمثيلات ثلاثية الأبعاد من الصور ثنائية الأبعاد ويمكن استخدامها لإنشاء تمثيلات ثلاثية الأبعاد عالية الجودة للهياكل البيولوجية أو المباني.

هناك نهجان لتقدير العمق:

* ستيريو: يتم تقدير العمق عن طريق مقارنة صورتين لنفس الصورة من زوايا مختلفة قليلاً
* أحادية العين: يتم تقدير العمق من صورة واحدة

```py
>>> from transformers import pipeline

>>> depth_estimator = pipeline(task="depth-estimation")
>>> preds = depth_estimator(
...     "https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/pipeline-cat-chonk.jpeg"
... )
```

## معالجة اللغات الطبيعية

تعد مهام NLP من بين أكثر أنواع المهام شيوعًا لأن النص هو طريقة طبيعية جدًا للتواصل معنا. وللحصول على نص بتنسيق يتعرف عليه النموذج، يجب توكيده. وهذا يعني تقسيم تسلسل النص إلى كلمات أو أجزاء كلمات منفصلة (رموز) ثم تحويل هذه الرموز إلى أرقام. ونتيجة لذلك، يمكنك تمثيل تسلسل نصي كتسلسل من الأرقام، وبمجرد حصولك على تسلسل من الأرقام، يمكن إدخاله في نموذج لحل جميع أنواع مهام NLP!

### تصنيف النصوص

مثل مهام التصنيف في أي طريقة، يقوم تصنيف النص بوضع علامة على تسلسل نصي (يمكن أن يكون على مستوى الجملة أو فقرة أو مستند) من مجموعة محددة مسبقًا من الفئات. هناك العديد من التطبيقات العملية لتصنيف النصوص، والتي تشمل:

* تحليل المشاعر: وضع علامة على النص وفقًا لبعض القطبية مثل `الإيجابية` أو `السلبية` والتي يمكن أن تُعلم وتدعم عملية صنع القرار في مجالات مثل السياسة والمالية والتسويق
* تصنيف المحتوى: وضع علامة على النص وفقًا لبعض الموضوعات للمساعدة في تنظيم المعلومات وتصفيتها في الأخبار والتغذية وسائل التواصل الاجتماعي (`الطقس`، `الرياضة`، `التمويل`، إلخ)

```py
>>> from transformers import pipeline

>>> classifier = pipeline(task="sentiment-analysis")
>>> preds = classifier("Hugging Face is the best thing since sliced bread!")
>>> preds = [{"score": round(pred["score"], 4), "label": pred["label"]} for pred in preds]
>>> preds
[{'score': 0.9991, 'label': 'POSITIVE'}]
```

### تصنيف الرموز

في أي مهمة NLP، تتم معالجة النص عن طريق فصل تسلسل النص إلى كلمات أو أجزاء كلمات منفصلة. هذه هي ما يعرف باسم [الرموز](glossary#token). يقوم تصنيف الرموز بتخصيص تسمية لكل رمز من مجموعة محددة مسبقًا من الفئات.

هناك نوعان شائعان من تصنيف الرموز:

* التعرف على الكيانات المسماة (NER): وضع علامة على الرمز وفقًا لفئة الكيان مثل المنظمة أو الشخص أو الموقع أو التاريخ. يعد NER شائعًا بشكل خاص في الإعدادات الطبية الحيوية، حيث يمكنه وضع علامات على الجينات والبروتينات وأسماء الأدوية.
* وضع العلامات النحوية (POS): وضع علامة على الرمز وفقًا لجزء الكلام الخاص به مثل الاسم أو الفعل أو الصفة. POS مفيد لمساعدة أنظمة الترجمة على فهم كيفية اختلاف كلمتين متطابقتين نحويًا (المصرف كاسم مقابل المصرف كفعل).

```py
>>> from transformers import pipeline

>>> classifier = pipeline(task="ner")
>>> preds = classifier("Hugging Face is a French company based in New York City.")
>>> preds = [
...     {
...         "entity": pred["entity"],
...         "score": round(pred["score"], 4),
...         "index": pred["index"],
...         "word": pred["word"],
...         "start": pred["start"],
...         "end": pred["end"],
...     }
...     for pred in preds
... ]
>>> print(*preds, sep="\n")
{'entity': 'I-ORG', 'score': 0.9968, 'index': 1, 'word': 'Hu', 'start': 0, 'end': 2}
{'entity': 'I-ORG', 'score': 0.9293, 'index': 2, 'word': '##gging', 'start': 2, 'end': 7}
{'entity': 'I-ORG', 'score': 0.9763, 'index': 3, 'word': 'Face', 'start': 8, 'end': 12}
{'entity': 'I-MISC', 'score': 0.9983, 'index': 6, 'word': 'French', 'start': 18, 'end': 24}
{'entity': 'I-LOC', 'score': 0.999, 'index': 10, 'word': 'New', 'start': 42, 'end': 45}
{'entity': 'I-LOC', 'score': 0.9987, 'index': 11, 'word': 'York', 'start': 46, 'end': 50}
{'entity': 'I-LOC', 'score': 0.9992, 'index': 12, 'word': 'City', 'start': 51, 'end': 55}
```
### الإجابة على الأسئلة

الإجابة على الأسئلة هي مهمة أخرى على مستوى الرمز تعيد إجابة على سؤال، أحيانًا مع السياق (مفتوح المجال) وأحيانًا بدون سياق (مجال مغلق). تحدث هذه المهمة كلما سألنا مساعدًا افتراضيًا شيئًا مثل ما إذا كان المطعم مفتوحًا. يمكن أن يساعد أيضًا في دعم العملاء أو الدعم الفني ويساعد محركات البحث في استرداد المعلومات ذات الصلة التي تطلبها.

هناك نوعان شائعان من الإجابة على الأسئلة:

* الاستخراجية: بالنظر إلى سؤال وبعض السياق، فإن الإجابة هي جزء من النص من السياق الذي يجب على النموذج استخراجه
* التلخيصي: بالنظر إلى سؤال وبعض السياق، يتم إنشاء الإجابة من السياق؛ يتعامل نهج [`Text2TextGenerationPipeline`] مع هذا النهج التلخيصي بدلاً من [`QuestionAnsweringPipeline`] الموضح أدناه


```py
>>> from transformers import pipeline

>>> question_answerer = pipeline(task="question-answering")
>>> preds = question_answerer(
...     question="What is the name of the repository?",
...     context="The name of the repository is huggingface/transformers",
... )
>>> print(
...     f"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}"
... )
score: 0.9327, start: 30, end: 54, answer: huggingface/transformers
```

### التلخيص

ينشئ التلخيص نسخة أقصر من نص من نص أطول مع محاولة الحفاظ على معظم معنى المستند الأصلي. التلخيص هو مهمة تسلسل إلى تسلسل؛ فهو يخرج تسلسل نص أقصر من الإدخال. هناك الكثير من الوثائق الطويلة التي يمكن تلخيصها لمساعدة القراء على فهم النقاط الرئيسية بسرعة. مشاريع القوانين والوثائق القانونية والمالية وبراءات الاختراع والأوراق العلمية هي مجرد أمثلة قليلة للوثائق التي يمكن تلخيصها لتوفير وقت القراء وخدمة كمساعد للقراءة.

مثل الإجابة على الأسئلة، هناك نوعان من التلخيص:

* الاستخراجية: تحديد واستخراج الجمل الأكثر أهمية من النص الأصلي
* التلخيصي: إنشاء ملخص الهدف (الذي قد يتضمن كلمات جديدة غير موجودة في وثيقة الإدخال) من النص الأصلي؛ يستخدم النهج التلخيصي [`SummarizationPipeline`]

```py
>>> from transformers import pipeline

>>> summarizer = pipeline(task="summarization")
>>> summarizer(
...     "In this work, we presented the Transformer, the first sequence transduction model based entirely on attention, replacing the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention. For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers. On both WMT 2014 English-to-German and WMT 2014 English-to-French translation tasks, we achieve a new state of the art. In the former task our best model outperforms even all previously reported ensembles."
... )
[{'summary_text': ' The Transformer is the first sequence transduction model based entirely on attention . It replaces the recurrent layers most commonly used in encoder-decoder architectures with multi-headed self-attention . For translation tasks, the Transformer can be trained significantly faster than architectures based on recurrent or convolutional layers .'}]
```

### الترجمة

تترجم الترجمة تسلسل نص بلغة واحدة إلى لغة أخرى. من المهم مساعدة الأشخاص من خلفيات مختلفة على التواصل مع بعضهم البعض، ومساعدة المحتوى على الوصول إلى جمهور أوسع، وحتى أن يكون أداة تعليمية لمساعدة الأشخاص على تعلم لغة جديدة. إلى جانب التلخيص، تعد الترجمة مهمة تسلسل إلى تسلسل، مما يعني أن النموذج يتلقى تسلسل إدخال ويعيد تسلسل الإخراج المستهدف.

في الأيام الأولى، كانت نماذج الترجمة في الغالب أحادية اللغة، ولكن مؤخرًا، كان هناك اهتمام متزايد بالنماذج متعددة اللغات التي يمكنها الترجمة بين العديد من أزواج اللغات.

```py
>>> from transformers import pipeline

>>> text = "translate English to French: Hugging Face is a community-based open-source platform for machine learning."
>>> translator = pipeline(task="translation", model="google-t5/t5-small")
>>> translator(text)
[{'translation_text': "Hugging Face est une tribune communautaire de l'apprentissage des machines."}]
```

### نمذجة اللغة

نمذجة اللغة هي مهمة التنبؤ بكلمة في تسلسل نص. لقد أصبح مهمة NLP شائعة للغاية لأن النموذج اللغوي المسبق التدريب يمكن أن يتم ضبطه بشكل دقيق للعديد من مهام التدفق السفلي الأخرى. في الآونة الأخيرة، كان هناك الكثير من الاهتمام بنماذج اللغة الكبيرة (LLMs) التي توضح التعلم الصفري أو القليل من التعلم. وهذا يعني أن النموذج يمكنه حل المهام التي لم يتم تدريبه عليها بشكل صريح! يمكن استخدام نماذج اللغة لإنشاء نص سلس ومقنع، على الرغم من أنه يجب أن تكون حذرًا لأن النص قد لا يكون دائمًا دقيقًا.

هناك نوعان من نمذجة اللغة:

* السببية: هدف النموذج هو التنبؤ بالرمز التالي في تسلسل، ويتم إخفاء الرموز المستقبلية

```py
>>> from transformers import pipeline

>>> prompt = "Hugging Face is a community-based open-source platform for machine learning."
>>> generator = pipeline(task="text-generation")
>>> generator(prompt)  # doctest: +SKIP
```

* الأقنعة: هدف النموذج هو التنبؤ برمز مقنع في تسلسل مع الوصول الكامل إلى الرموز في التسلسل

```py
>>> text = "Hugging Face is a community-based open-source <mask> for machine learning."
>>> fill_mask = pipeline(task="fill-mask")
>>> preds = fill_mask(text, top_k=1)
>>> preds = [
...     {
...         "score": round(pred["score"], 4),
...         "token": pred["token"],
...         "token_str": pred["token_str"],
...         "sequence": pred["sequence"],
...     }
...     for pred in preds
... ]
>>> preds
[{'score': 0.2236,
  'token': 1761,
  'token_str': ' platform',
  'sequence': 'Hugging Face is a community-based open-source platform for machine learning.'}]
```
  
## متعدد الوسائط:

تتطلب المهام متعددة الوسائط من النموذج معالجة وسائط بيانات متعددة (نص أو صورة أو صوت أو فيديو) لحل مشكلة معينة. يعد إنشاء عنوان الصورة مثالاً على مهمة متعددة الوسائط حيث يأخذ النموذج صورة كإدخال وينتج تسلسل نصي يصف الصورة أو بعض خصائصها.

على الرغم من أن النماذج متعددة الوسائط تعمل مع أنواع بيانات أو طرائق مختلفة، إلا أن خطوات المعالجة المسبقة تساعد النموذج داخليًا على تحويل جميع أنواع البيانات إلى تضمينات (متجهات أو قوائم من الأرقام التي تحتوي على معلومات ذات معنى حول البيانات). بالنسبة لمهمة مثل إنشاء عنوان للصورة، يتعلم النموذج العلاقات بين تضمينات الصور وتضمينات النص.

### الإجابة على أسئلة المستندات:

الإجابة على أسئلة المستندات هي مهمة تقوم بالإجابة على أسئلة اللغة الطبيعية من مستند. على عكس مهمة الإجابة على الأسئلة على مستوى الرمز التي تأخذ النص كإدخال، فإن الإجابة على أسئلة المستندات تأخذ صورة لمستند كإدخال بالإضافة إلى سؤال حول المستند وتعيد الإجابة. يمكن استخدام الإجابة على أسئلة المستندات لتفسير المستندات المهيكلة واستخراج المعلومات الرئيسية منها. في المثال أدناه، يمكن استخراج المبلغ الإجمالي والتغيير المستحق من الإيصال.

```py
>>> from transformers import pipeline
>>> from PIL import Image
>>> import requests

>>> url = "https://huggingface.co/datasets/hf-internal-testing/example-documents/resolve/main/jpeg_images/2.jpg"
>>> image = Image.open(requests.get(url, stream=True).raw)

>>> doc_question_answerer = pipeline("document-question-answering", model="magorshunov/layoutlm-invoices")
>>> preds = doc_question_answerer(
...     question="ما هو المبلغ الإجمالي؟",
...     image=image,
... )
>>> preds
[{'score': 0.8531, 'answer': '17,000', 'start': 4, 'end': 4}]
```

نأمل أن تكون هذه الصفحة قد زودتك ببعض المعلومات الأساسية حول جميع أنواع المهام في كل طريقة وأهمية كل منها العملية. في القسم التالي، ستتعلم كيف تعمل مكتبة 🤗 Transformers لحل هذه المهام.