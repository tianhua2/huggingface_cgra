# ุชูุงูู XLA ูููุงุฐุฌ TensorFlow

[[open-in-colab]]

ุงูุฌุจุฑ ุงูุฎุทู ุงููุนุฌูุ ุงูุฐู ููุทูู ุนููู XLAุ ูู ูุชุฑุฌู ูุชุณุฑูุน ููุช ุชุดุบูู ููุงุฐุฌ TensorFlow. ูู [ุงููุซุงุฆู ุงูุฑุณููุฉ](https://www.tensorflow.org/xla):

> XLA (Accelerated Linear Algebra) ูู ูุชุฑุฌู ุฎุงุต ุจุงููุฌุงู ููุฌุจุฑ ุงูุฎุทู ููููู ุชุณุฑูุน ููุงุฐุฌ TensorFlow ุฏูู ุฅุฌุฑุงุก ุฃู ุชุบููุฑุงุช ุนูู ุดูุฑุฉ ุงููุตุฏุฑ.

ุฅู ุงุณุชุฎุฏุงู XLA ูู TensorFlow ุฃูุฑ ุจุณูุท - ููู ูุฃุชู ูุถูููุง ุฏุงุฎู ููุชุจุฉ `tensorflow`ุ ููููู ุชุดุบููู ุจุงุณุชุฎุฏุงู ูุณูุท `jit_compile` ูู ุฃู ุฏุงูุฉ ูุฅูุดุงุก ุงูุฑุณู ุงูุจูุงูู ูุซู [`tf.function`](https://www.tensorflow.org/guide/intro_to_graphs). ุนูุฏ ุงุณุชุฎุฏุงู ุฃุณุงููุจ Keras ูุซู `fit()` ู`predict()`ุ ููููู ุชูููู XLA ุจุจุณุงุทุฉ ุนู ุทุฑูู ุชูุฑูุฑ ูุณูุท `jit_compile` ุฅูู `model.compile()`. ููุน ุฐููุ ูุง ุชูุชุตุฑ XLA ุนูู ูุฐู ุงูุฃุณุงููุจ - ูููู ุฃูุถูุง ุงุณุชุฎุฏุงููุง ูุชุณุฑูุน ุฃู ุฏุงูุฉ `tf.function` ุนุดูุงุฆูุฉ.

ุชูุช ุฅุนุงุฏุฉ ูุชุงุจุฉ ุงูุนุฏูุฏ ูู ุฃุณุงููุจ TensorFlow ูู ๐ค Transformers ูุชููู ูุชูุงููุฉ ูุน XLAุ ุจูุง ูู ุฐูู ุชูููุฏ ุงููุตูุต ูููุงุฐุฌ ูุซู [GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2) ู[T5](https://huggingface.co/docs/transformers/model_doc/t5) ู[OPT](https://huggingface.co/docs/transformers/model_doc/opt)ุ ุจุงูุฅุถุงูุฉ ุฅูู ูุนุงูุฌุฉ ุงูููุงู ูููุงุฐุฌ ูุซู [Whisper](https://huggingface.co/docs/transformers/model_doc/whisper).

ูู ุญูู ุฃู ููุฏุงุฑ ุงูุชุณุฑูุน ุงูุฏููู ูุนุชูุฏ ุฅูู ุญุฏ ูุจูุฑ ุนูู ุงููููุฐุฌุ ููุฏ ูุงุญุธูุง ุชุณุฑูุนูุง ูุจูุบ ุญูุงูู 100x ูููุงุฐุฌ ุชูููุฏ ุงููุตูุต TensorFlow ุฏุงุฎู ๐ค Transformers. ุณููุถุญ ูุฐุง ุงููุณุชูุฏ ููููุฉ ุงุณุชุฎุฏุงู XLA ููุฐู ุงูููุงุฐุฌ ููุญุตูู ุนูู ุฃูุตู ูุฏุฑ ูู ุงูุฃุฏุงุก. ููุง ุณููุฏู ุฑูุงุจุท ุฅูู ููุงุฑุฏ ุฅุถุงููุฉ ุฅุฐุง ููุช ููุชููุง ุจูุนุฑูุฉ ุงููุฒูุฏ ุญูู ุงููุนุงููุฑ ูุชูููุฑูุง ูู ุชุตููู ุงูุชูุงูู ูุน XLA.

## ุชุดุบูู ูุธุงุฆู TF ุจุงุณุชุฎุฏุงู XLA

ููุฃุฎุฐ ูู ุงูุงุนุชุจุงุฑ ุงููููุฐุฌ ุงูุชุงูู ูู TensorFlow:

```py
import tensorflow as tf

model = tf.keras.Sequential(
    [tf.keras.layers.Dense(10, input_shape=(10,), activation="relu"), tf.keras.layers.Dense(5, activation="softmax")]
)
```

ููุจู ุงููููุฐุฌ ุฃุนูุงู ุฅุฏุฎุงูุงุช ุฐุงุช ุจุนุฏ `(10, )`. ูููููุง ุงุณุชุฎุฏุงู ุงููููุฐุฌ ูุชุดุบูู ุนูููุฉ ุชูุฑูุฑ ุฃูุงูู ููุง ููู:

```py
# Generate random inputs for the model.
batch_size = 16
input_vector_dim = 10
random_inputs = tf.random.normal((batch_size, input_vector_dim))

# Run a forward pass.
_ = model(random_inputs)
```

ูุชุดุบูู ุนูููุฉ ุงูุชูุฑูุฑ ุงูุฃูุงูู ุจุงุณุชุฎุฏุงู ุฏุงูุฉ ูุฌูุนุฉ ุจูุงุณุทุฉ XLAุ ุณูุญุชุงุฌ ุฅูู ุงูููุงู ุจูุง ููู:

```py
xla_fn = tf.function(model, jit_compile=True)
_ = xla_fn(random_inputs)
```

ุชูุณุชุฎุฏู ุฏุงูุฉ `call()` ุงูุงูุชุฑุงุถูุฉ ูููููุฐุฌ ูุชุฌููุน ุฑุณู ุจูุงูู XLA. ูููู ุฅุฐุง ูุงู ููุงู ุฃู ุฏุงูุฉ ุฃุฎุฑู ูููููุฐุฌ ุชุฑูุฏ ุชุฌููุนูุง ูู XLAุ ูููููู ุฃูุถูุง ุงูููุงู ุจุฐูู:

```py
my_xla_fn = tf.function(model.my_xla_fn, jit_compile=True)
```

## ุชุดุบูู ูููุฐุฌ ุชูููุฏ ูุต TF ุจุงุณุชุฎุฏุงู XLA ูู ๐ค Transformers

ูุชูููู ุงูุชูููุฏ ุงููุนุฌู ุจูุงุณุทุฉ XLA ุฏุงุฎู ๐ค Transformersุ ูุฌุจ ุฃู ูููู ูุฏูู ุฅุตุฏุงุฑ ุญุฏูุซ ูู `transformers` ูุซุจุชูุง. ููููู ุชุซุจูุชู ุนู ุทุฑูู ุชุดุบูู:

```bash
pip install transformers --upgrade
```

ุซู ููููู ุชุดุบูู ุงูุดูุฑุฉ ุงูุชุงููุฉ:

```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM
```bash
pip install transformers --upgrade
```

ุซู ููููู ุชุดุบูู ุงูุดูุฑุฉ ุงูุชุงููุฉ:

```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

# ุณูุญุฏุซ ุฎุทุฃ ุฅุฐุง ูู ูุชู ุชุซุจูุช ุงูุฅุตุฏุงุฑ ุงูุฃุฏูู ูู Transformers.
from transformers.utils import check_min_version

check_min_version("4.21.0")


tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("openai-community/gpt2")
input_string = ["TensorFlow is"]

# ุณุทุฑ ูุงุญุฏ ูุฅูุดุงุก ุฏุงูุฉ ุชูููุฏ XLA
xla_generate = tf.function(model.generate, jit_compile=True)

tokenized_input = tokenizer(input_string, return_tensors="tf")
generated_tokens = xla_generate(**tokenized_input, num_beams=2)

decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(f"Generated -- {decoded_text}")
# ุชู ุงูุชูููุฏ -- TensorFlow ูู ุฅุทุงุฑ ุชุทุจูู ููุชูุญ ุงููุตุฏุฑ ูููุชูุญ ุงููุตุฏุฑ ูููุชูุญ ุงููุตุฏุฑ
```

ููุง ุชูุงุญุธุ ูุฅู ุชูููู XLA ุนูู `generate()` ูู ูุฌุฑุฏ ุณุทุฑ ูุงุญุฏ ูู ุงูุดูุฑุฉ. ุชุธู ุจููุฉ ุงูุดูุฑุฉ ุฏูู ุชุบููุฑ. ููุน ุฐููุ ููุงู ุจุนุถ ุงูุฃุดูุงุก ุงูุชู ูุฌุจ ูุฑุงุนุงุชูุง ูู ููุชุทู ุงูุดูุฑุฉ ุฃุนูุงู ูุงูุชู ุชุฎุต XLA ุชุญุฏูุฏูุง. ูุฌุจ ุฃู ุชููู ุนูู ุฏุฑุงูุฉ ุจูุง ูุชุญููู ุงูุชุณุฑูุนุงุช ุงูุชู ูููู ุฃู ุชููุฑูุง XLA. ููุงูุด ูุฐู ุงูุฃููุฑ ูู ุงููุณู ุงูุชุงูู.

## ุงูุฃุดูุงุก ุงูุชู ูุฌุจ ูุฑุงุนุงุชูุง

ุนูุฏูุง ุชููู ุจุชูููุฐ ุฏุงูุฉ ูููููุฉ ูู XLA (ูุซู `xla_generate()` ุฃุนูุงู) ูููุฑุฉ ุงูุฃูููุ ูุณูู ุชุญุงูู ุฏุงุฎูููุง ุงุณุชูุชุงุฌ ุฑุณู ุงูุญุณุงุจุ ููู ุฃูุฑ ูุณุชุบุฑู ููุชูุง ุทูููุงู. ุชูุนุฑู ูุฐู ุงูุนูููุฉ ุจุงุณู ["ุงูุชุชุจุน"](https://www.tensorflow.org/guide/intro_to_graphs#when_is_a_function_tracing).

ูุฏ ุชูุงุญุธ ุฃู ููุช ุงูุชูููุฏ ููุณ ุณุฑูุนูุง. ูู ุชุญุชุงุฌ ุนูููุงุช ุงูุงุณุชุฏุนุงุก ุงููุชุชุงููุฉ ูู `xla_generate()` (ุฃู ุฃู ุฏุงูุฉ ุฃุฎุฑู ูููููุฉ ูู XLA) ุฅูู ุงุณุชูุชุงุฌ ุฑุณู ุงูุญุณุงุจุ ุจุดุฑุท ุฃู ุชุชุจุน ุงูุฅุฏุฎุงูุงุช ุฅูู ุงูุฏุงูุฉ ููุณ ุงูุดูู ุงูุฐู ุชู ุจูุงุก ุฑุณู ุงูุญุณุงุจ ุจู ูู ุงูุจุฏุงูุฉ. ูู ุญูู ุฃู ูุฐุง ููุณ ูุดููุฉ ุจุงููุณุจุฉ ููุทุฑุงุฆู ุฐุงุช ุฃุดูุงู ุงูุฅุฏุฎุงู ุงูุซุงุจุชุฉ (ูุซู ุงูุตูุฑ)ุ ูุฌุจ ุงูุงูุชุจุงู ุฅุฐุง ููุช ุชุนูู ูุน ุทุฑุงุฆู ุฐุงุช ุดูู ุฅุฏุฎุงู ูุชุบูุฑ (ูุซู ุงููุต).

ูุถูุงู ุนูู `xla_generate()` ุฏุงุฆููุง ูุน ุฃุดูุงู ุงูุฅุฏุฎุงู ููุณูุงุ ููููู ุชุญุฏูุฏ ูุณูุทุงุช `padding` ุนูุฏ ุงุณุชุฏุนุงุก tokenizer.

```py
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("openai-community/gpt2")
input_string = ["TensorFlow is"]

xla_generate = tf.function(model.generate, jit_compile=True)

# ููุงุ ูููู ุจุงุณุชุฏุนุงุก tokenizer ูุน ุฎูุงุฑุงุช ุงูุญุดู.
tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors="tf")

generated_tokens = xla_generate(**tokenized_input, num_beams=2)
decoded_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)
print(f"Generated -- {decoded_text}")
```

ุจูุฐู ุงูุทุฑููุฉุ ููููู ุงูุชุฃูุฏ ูู ุฃู ุงูุฅุฏุฎุงูุงุช ุฅูู `xla_generate()` ุณุชุชููู ุฏุงุฆููุง ุฅุฏุฎุงูุงุช ุฐุงุช ุงูุดูู ุงูุฐู ุชู ุชุชุจุนู ุจูุ ููุง ูุคุฏู ุฅูู ุชุณุฑูุน ููุช ุงูุชูููุฏ. ููููู ุงูุชุญูู ูู ุฐูู ุจุงุณุชุฎุฏุงู ุงูุดูุฑุฉ ุงูุชุงููุฉ:

```py
import time
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained("openai-community/gpt2", padding_side="left", pad_token="</s>")
model = TFAutoModelForCausalLM.from_pretrained("openai-community/gpt2")

xla_generate = tf.function(model.generate, jit_compile=True)

for input_string in ["TensorFlow is", "TensorFlow is a", "TFLite is a"]:
    tokenized_input = tokenizer(input_string, pad_to_multiple_of=8, padding=True, return_tensors="tf")
    start = time.time_ns()
    generated_tokens = xla_generate(**tokenized_input, num_beams=2)
    end = time.time_ns()
    print(f"Execution time -- {(end - start) / 1e6:.1f} ms\n")
```

ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) Tesla T4ุ ููููู ุชููุน ุงููุฎุฑุฌุงุช ููุง ููู:

```bash
Execution time -- 30819.6 ms
ุนูู ูุญุฏุฉ ูุนุงูุฌุฉ ุงูุฑุณูููุงุช (GPU) Tesla T4ุ ููููู ุชููุน ุงููุฎุฑุฌุงุช ููุง ููู:

```bash
Execution time -- 30819.6 ms

Execution time -- 79.0 ms

Execution time -- 78.9 ms
```
ุชุณุชุบุฑู ุงูููุงููุฉ ุงูุฃููู ุฅูู `xla_generate()` ููุชูุง ุทูููุงู ุจุณุจุจ ุงูุชุชุจุนุ ูููู ุงูููุงููุงุช ุงููุชุชุงููุฉ ุฃุณุฑุน ุจูุซูุฑ. ุถุน ูู ุงุนุชุจุงุฑู ุฃู ุฃู ุชุบููุฑ ูู ุฎูุงุฑุงุช ุงูุชูููุฏ ูู ุฃู ููุทุฉ ุณูุคุฏู ุฅูู ุฅุนุงุฏุฉ ุงูุชุชุจุนุ ููุง ูุคุฏู ุฅูู ุจุทุก ููุช ุงูุชูููุฏ.

ูู ูุบุทู ุฌููุน ุฎูุงุฑุงุช ุชูููุฏ ุงููุตูุต ุงูุชู ูููุฑูุง ๐ค Transformers ูู ูุฐู ุงููุซููุฉ. ูุดุฌุนู ุนูู ูุฑุงุกุฉ ุงููุซุงุฆู ููุญุตูู ุนูู ุญุงูุงุช ุงุณุชุฎุฏุงู ูุชูุฏูุฉ.

## ููุงุฑุฏ ุฅุถุงููุฉ

ูุชุฑููู ููุง ุจุจุนุถ ุงูููุงุฑุฏ ุงูุฅุถุงููุฉ ุฅุฐุง ููุช ุชุฑุบุจ ูู ุงูุชุนูู ูู XLA ูู ๐ค Transformers ุจุดูู ุนุงู.

* [ูููุฑ ุฏูุชุฑ ุงูููุงุญุธุงุช ูุฐุง ูู Colab](https://colab.research.google.com/github/huggingface/blog/blob/main/notebooks/91_tf_xla_generate.ipynb) ุนุฑุถูุง ุชูุถูุญููุง ุชูุงุนูููุง ุฅุฐุง ููุช ุชุฑุบุจ ูู ุงูุนุจุซ ุจููุงุฐุฌ ุงูุชูููุฏ ุงููุชูุงููุฉ ูุน XLA (ูุซู [T5](https://huggingface.co/docs/transformers/model_doc/t5)) ูุงูุชุฑููุฒ ูู ุงูุชุฑููุฒ (ูุซู [GPT2](https://huggingface.co/docs/transformers/model_doc/gpt2)).
* [ุชูุฏู ูุฐู ุงูุชุฏูููุฉ](https://huggingface.co/blog/tf-xla-generate) ูุธุฑุฉ ุนุงูุฉ ุนูู ูุนุงููุฑ ุงูููุงุฑูุฉ ููููุงุฐุฌ ุงููุชูุงููุฉ ูุน XLA ุจุงูุฅุถุงูุฉ ุฅูู ููุฏูุฉ ุณููุฉ ุงูุงุณุชุฎุฏุงู ูู XLA ูู TensorFlow.
* [ุชูุงูุด ูุฐู ุงูุชุฏูููุฉ](https://blog.tensorflow.org/2022/11/how-hugging-face-improved-text-generation-performance-with-xla.html) ุชูููุฑูุง ูู ุงูุชุตููู ูุฑุงุก ุฅุถุงูุฉ ุฏุนู XLA ุฅูู ููุงุฐุฌ TensorFlow ูู ๐ค Transformers.
* ุงููุดุงุฑูุงุช ุงูููุตู ุจูุง ููุนุฑูุฉ ุงููุฒูุฏ ุญูู XLA ูุฑุณููุงุช TensorFlow ุจุดูู ุนุงู:
    * [XLA: ูุชุฑุฌู ูุญุณูู ูุชุนูู ุงูุขูุฉ](https://www.tensorflow.org/xla)
    * [ููุฏูุฉ ุฅูู ุงูุฑุณูู ุงูุจูุงููุฉ ูtf.function](https://www.tensorflow.org/guide/intro_to_graphs)
    * [ุฃุฏุงุก ุฃูุถู ูุน tf.function](https://www.tensorflow.org/guide/function)